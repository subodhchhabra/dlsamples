{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import mxnet as mx\n",
    "\n",
    "# Download pre-trained Resnet-18 model to directory\n",
    "# For downloading a file to local disk\n",
    "def download(url,target_dir):\n",
    "    filename = url.split('/')[-1]\n",
    "    if not os.path.exists(os.path.join(target_dir,filename)):\n",
    "        urllib.request.urlretrieve(url,os.path.join(target_dir,filename))\n",
    "        \n",
    "download('http://data.dmlc.ml/mxnet/models/imagenet/resnet/18-layers/resnet-18-0000.params','./model')\n",
    "download('http://data.dmlc.ml/mxnet/models/imagenet/resnet/18-layers/resnet-18-symbol.json','./model')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "# Load the pre-trained model\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('./model/resnet-18', 0)\n",
    "\n",
    "# Get Data Iterators  image data and labels.\n",
    "def get_iterators(batch_size, data_shape=(3, 224, 224)):\n",
    "    train = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = './data/cars_train.rec',\n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        shuffle             = True,\n",
    "        rand_crop           = True,\n",
    "        rand_mirror         = True)\n",
    "    val = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = './data/cars_val.rec',\n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        rand_crop           = False,\n",
    "        rand_mirror         = False)\n",
    "    return (train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the ImageNet 1000 layer classification layer and attach 196 dimensional cars layer\n",
    "def get_fine_tune_model(symbol, arg_params, num_classes, layer_name='flatten0'):\n",
    "    \"\"\"\n",
    "    symbol: the pretrained network symbol\n",
    "    arg_params: the argument parameters of the pretrained model\n",
    "    num_classes: the number of classes for the fine-tune datasets\n",
    "    layer_name: the layer name before the last fully-connected layer\n",
    "    \"\"\"\n",
    "    all_layers = symbol.get_internals()\n",
    "    net = all_layers[layer_name+'_output'] # remove the original fully connected layer\n",
    "    net = mx.symbol.FullyConnected(data=net, num_hidden=num_classes, name='fc1')\n",
    "    net = mx.symbol.SoftmaxOutput(data=net, name='softmax')\n",
    "    mx.viz.plot_network(net) # Visualize the network\n",
    "    new_args = dict({k:arg_params[k] for k in arg_params if 'fc1' not in k})\n",
    "    return (net, new_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "import logging\n",
    "head = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=head)\n",
    "\n",
    "def fit(symbol, arg_params, aux_params, train, val, batch_size, num_gpus, num_epoch):\n",
    "    devs = [mx.gpu(i) for i in range(num_gpus)]\n",
    "    mod = mx.mod.Module(symbol=symbol, context=devs)\n",
    "    mod.fit(train, val,\n",
    "        num_epoch=num_epoch, # Number of epochs\n",
    "        arg_params=arg_params,\n",
    "        aux_params=aux_params,\n",
    "        allow_missing=True,\n",
    "        batch_end_callback = mx.callback.Speedometer(batch_size, 10),\n",
    "        kvstore='device',\n",
    "        optimizer='sgd',\n",
    "            #adam or sgd\n",
    "        optimizer_params={'learning_rate':0.02}, # Learning rate\n",
    "        initializer=mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=2),\n",
    "        eval_metric='acc',\n",
    "        epoch_end_callback = mx.callback.do_checkpoint('./model/cars-finetuned'))\n",
    "    metric = mx.metric.Accuracy()\n",
    "    return mod.score(val, metric)\n",
    "\n",
    "num_classes = 196 # Number of categories in cars dataset\n",
    "batch_per_gpu = 200 # Batch size\n",
    "num_gpus = 1 # Since we only have a single GPU\n",
    "num_epoch = 500 # Number of epochs that we are going to train for\n",
    "\n",
    "(new_sym, new_args) = get_fine_tune_model(sym, arg_params, num_classes)\n",
    "\n",
    "batch_size = batch_per_gpu * num_gpus\n",
    "(train, val) = get_iterators(batch_size)\n",
    "mod_score = fit(new_sym, new_args, aux_params, train, val, batch_size, num_gpus, num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the finetuned model for prediction on new images\n",
    "import scipy.io # if this fails, install scipy 'conda install scipy'\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    " \n",
    "# define a simple data batch\n",
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])\n",
    "\n",
    "num_epoch = 239\n",
    "\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('./model/cars-finetuned', num_epoch)\n",
    "mod = mx.mod.Module(symbol=sym, context=mx.gpu(), label_names=None)\n",
    "mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "         label_shapes=mod._label_shapes)\n",
    "mod.set_params(arg_params, aux_params, allow_missing=True)\n",
    "\n",
    "# Load the label file for getting car name\n",
    "label_file = scipy.io.loadmat('./data/cars_annos.mat')\n",
    "\n",
    "\n",
    "def get_image(url, show=False):\n",
    "    # download and show the image\n",
    "    fname = mx.test_utils.download(url)\n",
    "    img = cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB)\n",
    "    if img is None:\n",
    "         return None\n",
    "    if show:\n",
    "         plt.imshow(img)\n",
    "         plt.axis('off')\n",
    "    # convert into format (batch, RGB, width, height)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)\n",
    "    img = img[np.newaxis, :]\n",
    "    return img\n",
    "\n",
    "def predict(url,label_file):\n",
    "    img = get_image(url, show=True)\n",
    "    # compute the predict probabilities\n",
    "    mod.forward(Batch([mx.nd.array(img)]))\n",
    "    prob = mod.get_outputs()[0].asnumpy()\n",
    "    # print the top-5\n",
    "    prob = np.squeeze(prob)\n",
    "    a = np.argsort(prob)[::-1]\n",
    "    object_categories = [i[0] for i in label_file['class_names'][0]]\n",
    "    for i in a[0:5]:\n",
    "        print('probability=%f, class=%s' %(prob[i], object_categories[i]))\n",
    "\n",
    "# Get prediction on an image\n",
    "\n",
    "test_url = 'http://ai.stanford.edu/~jkrause/cars/car5.jpg'\n",
    "#test_url = ''\n",
    "predict(test_url,label_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mxnet_p36]",
   "language": "python",
   "name": "conda-env-mxnet_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
